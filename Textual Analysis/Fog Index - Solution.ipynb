{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fog Index\n",
    "\n",
    "In this module, we will be learning how to compute the Gunning Fog index.\n",
    "\n",
    "Before we begin, let's import the modules we'll be using in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from MyFunctions import html_to_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fog Index Background and Computation\n",
    "\n",
    "The Gunning Fog index is a measure of the readability of a disclosure. The index estimates the years of formal education a person needs to understand a text on the first reading. For example, a fog index of 12 requires 12 years of education (i.e., high school graduate). A fog index of 16 requires 16 years of education (i.e., college graduate).\n",
    "\n",
    "Feng Li was the first to introduce the fog index to the accounting literature in his 2008 *Journal of Accounting and Economics* paper. He found that annual reports of firms with higher fog indices have lower and less persistent earnings. Other papers have extended the literature to measure readability differently (e.g., 10-K file size, the BOG index, etc.).\n",
    "\n",
    "The Fog index is calculated as follows:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "FOG = 0.4\\ \\bigl[\\ \\bigl(\\frac{\\#\\ WORDS}{\\#\\ SENTENCES}\\bigr) + 100\\ \\bigl(\\frac{\\#\\ COMPLEX\\ WORDS}{\\#\\ WORDS}\\bigr)\\ \\bigr]\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Disclosure\n",
    "\n",
    "To illustrate the computation of the fog index, we'll be using Apple's 10-K for its 2011 fiscal year (https://www.sec.gov/Archives/edgar/data/320193/000119312511282113/d220209d10k.htm). \n",
    "\n",
    "Let's import this filing using the **requests.get** function and then convert the html source code to text using the **html_to_text** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUG 2021 UPDATE -- YOU HAVE TO DECLARE A HEADER TO ACCESS THE EDGAR WEBSITE\n",
    "\n",
    "headers = {'User-Agent': 'ORGANIZATION youremail@yourinstitution.edu'}\n",
    "html = requests.get('https://www.sec.gov/Archives/edgar/data/320193/000119312511282113/d220209d10k.htm',headers=headers).text\n",
    "text = html_to_text(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Words\n",
    "\n",
    "We can use the **word_tokenize** function to obtain a list of all words in the disclosure. We'll strip out non-alphabetic tokens (e.g., punctuation, numbers), and then we can obtain the total word count using the **len** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text)\n",
    "\n",
    "# Remove non-alphabetic (i.e., punctuation, numbers) tokens\n",
    "    \n",
    "words = [w for w in words if w.isalpha()]\n",
    "\n",
    "# Compute the number of words\n",
    "\n",
    "num_words = len(words)\n",
    "\n",
    "num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Sentences\n",
    "\n",
    "We can use the **sent_tokenize** function to obtain a list of all sentences in the disclosure. We'll remove sentences that are three words or fewer since these are likely not truly sentences but rather are data found in the disclsoure.  We can then obtain the total sentence count using the **len** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "\n",
    "# Remove sentences that are 3 words or fewer\n",
    "\n",
    "sentences = [s for s in sentences if len(s.split(' ')) > 3]\n",
    "\n",
    "# Compute the number of sentences\n",
    "\n",
    "num_sentences = len(sentences)\n",
    "\n",
    "num_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Complex Words\n",
    "\n",
    "Complex words are words consisting of three or more syllables.\n",
    "\n",
    "We can calculate the number of syllables in a word using the Carnegie Mellon University Pronouncing Dictionary (CMUDICT). The CMUDICT is an open-source machine-readable pronunciation dictionary for North American English that contains over 134,000 words and their pronunciations (see http://www.speech.cs.cmu.edu/cgi-bin/cmudict).\n",
    "\n",
    "The **nltk** module contains this pronunciation dictionary. Let's import it and use it to count the number of syllables in a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('cmudict')\n",
    "\n",
    "from nltk.corpus import cmudict\n",
    "cmu = cmudict.dict()\n",
    "\n",
    "word = 'disclosure'\n",
    "cmu[word.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pronunciation = ''.join(cmu[word.lower()][0])\n",
    "word_pronunciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_syl = len(re.findall(r'\\d', word_pronunciation))\n",
    "num_syl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_syllables(word):\n",
    "    try:\n",
    "        word_pronunciation = ''.join(cmu[word.lower()][0])\n",
    "        num_syl = len(re.findall(r'\\d', word_pronunciation))\n",
    "    except Exception:\n",
    "        if len(word) >= 10:\n",
    "            num_syl = 3\n",
    "        else:\n",
    "            num_syl = 1\n",
    "    return num_syl\n",
    "\n",
    "print(num_syllables('disclosure'))\n",
    "print(num_syllables('strategically'))\n",
    "print(num_syllables('interestingly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the number of complex words using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_words = [w for w in words if num_syllables(w) >= 3]\n",
    "\n",
    "num_complex_words = len(complex_words)\n",
    "\n",
    "num_complex_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Fog\n",
    "\n",
    "We now have everything we need to calculate Fog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate words per sentence\n",
    "\n",
    "words_per_sentence = num_words/num_sentences\n",
    "\n",
    "# Calculate the percentage of complex words\n",
    "\n",
    "percent_complex_words = (num_complex_words/num_words) * 100\n",
    "\n",
    "# Calculate Fog\n",
    "\n",
    "fog = 0.4 * (words_per_sentence + percent_complex_words)\n",
    "\n",
    "fog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "1. Create a function called **get_fog** that takes the EDGAR URL as input and returns the **fog** of the disclosure.\n",
    "2. Calculate **fog** for Target's 10-K for the fiscal period ending February 1, 2020 (https://www.sec.gov/Archives/edgar/data/27419/000002741920000008/tgt-20200201.htm).\n",
    "3. Calculate **fog** for Walmart's 10-K for the fiscal period ending January 31, 2020 (https://www.sec.gov/Archives/edgar/data/104169/000010416920000011/wmtform10-kx1312020.htm). Compare Walmart's fog index to Target's fog index? What does this difference suggest about the readability of Walmart's 10-K relative to Target's 10-K?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution for # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fog(url):\n",
    "    \n",
    "    # Obtain the text of the disclosure\n",
    "    \n",
    "    headers = {'User-Agent': 'ORGANIZATION youremail@yourinstitution.edu'}\n",
    "    disclosure = requests.get(url,headers=headers).text\n",
    "    text = html_to_text(disclosure)\n",
    "    \n",
    "    # Compute the number of words\n",
    "    \n",
    "    words = word_tokenize(text) # Obtain word tokens\n",
    "    words = [w for w in words if w.isalpha()] # Remove non-alphabetic (i.e., punctuation, numbers) tokens\n",
    "    num_words = len(words)\n",
    "\n",
    "    # Compute the number of sentences\n",
    "    \n",
    "    sentences = sent_tokenize(text) # Obtain sentence tokens\n",
    "    sentences = [s for s in sentences if len(s.split(' ')) > 3] # Remove sentences that are 3 words or fewer\n",
    "    num_sentences = len(sentences)\n",
    "    \n",
    "    # Compute the number of complex words\n",
    "    \n",
    "    complex_words = [w for w in words if num_syllables(w) >= 3]\n",
    "    num_complex_words = len(complex_words)\n",
    "\n",
    "    # Calculate Fog\n",
    "    \n",
    "    words_per_sentence = num_words/num_sentences\n",
    "    percent_complex_words = (num_complex_words/num_words) * 100\n",
    "    fog = 0.4 * (words_per_sentence + percent_complex_words)\n",
    "\n",
    "    return fog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution for # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "\n",
    "fog = get_fog('https://www.sec.gov/Archives/edgar/data/27419/000002741920000008/tgt-20200201.htm')\n",
    "\n",
    "print('Fog is equal to '+'{:.3f}'.format(fog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution for # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walmart\n",
    "\n",
    "fog = get_fog('https://www.sec.gov/Archives/edgar/data/104169/000010416920000011/wmtform10-kx1312020.htm')\n",
    "\n",
    "print('Fog is equal to '+'{:.3f}'.format(fog))\n",
    "\n",
    "# The fog index for Walmart is higher than the fog index for Target\n",
    "# suggesting that Walmart's 10-K is less readable than Target's 10-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
